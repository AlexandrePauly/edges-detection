{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recognition in natural environments II : Image Data Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D66qulqJUXcu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Suppress deprecation warnings\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data are loaded by batch during training time and prediction time to avoid crash kernel issue. It's the reason why we are using a start and limit parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn7vxwJVUXcw"
      },
      "outputs": [],
      "source": [
        "def load_images(image_dir, labels_dir, start, limit):\n",
        "    # Initialization of variables\n",
        "    images = []    # List to store input images\n",
        "    labels = []    # List to store labels images\n",
        "    filenames = [] # List to store file names\n",
        "\n",
        "    # List all jpg files and sort them alphabetically\n",
        "    all_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
        "\n",
        "    # Slice the sorted list to get the required range\n",
        "    selected_files = all_files[start:start+limit]\n",
        "\n",
        "    for filename in selected_files:\n",
        "        # Reading images\n",
        "        image = cv2.imread(os.path.join(image_dir, filename))\n",
        "        label = cv2.imread(os.path.join(labels_dir, filename.replace('.jpg', '.png')), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is not None and label is not None:\n",
        "            images.append(cv2.resize(image, (428, 240)))  # Resize to 428x240\n",
        "            labels.append(cv2.resize(label, (428, 240)))  # Resize to 428x240\n",
        "            filenames.append(filename)\n",
        "\n",
        "    return np.array(images), np.array(labels), filenames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pre-processing : Normalization of inputs and binarisation of labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kabzn91pUXcx"
      },
      "outputs": [],
      "source": [
        "# Preprocess images and labels\n",
        "def preprocess_data(images, labels):\n",
        "    # Inputs normalization\n",
        "    images = images.astype('float32') / 255.0\n",
        "\n",
        "    # Labels binarization\n",
        "    labels = (labels > 0).astype('float32')\n",
        "    labels = np.expand_dims(labels, axis=-1)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predictions model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### UNet\n",
        "This model give the best predictions (including post-processing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4rov-YWUXcy"
      },
      "outputs": [],
      "source": [
        "# U-Net model\n",
        "def UNet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Downsample\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # Upsample\n",
        "    u1 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv3)\n",
        "    u1 = layers.concatenate([u1, conv2])\n",
        "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    u2 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv4)\n",
        "    u2 = layers.concatenate([u2, conv1])\n",
        "    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
        "    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv5)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### UNet more complex\n",
        "Don't works because the kernel of the laptop crash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def UNet_deeper(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Downsample\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # Upsample\n",
        "    u1 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv3)\n",
        "    u1 = layers.concatenate([u1, conv2])\n",
        "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
        "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    u2 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv4)\n",
        "    u2 = layers.concatenate([u2, conv1])\n",
        "    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
        "    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Additional layers\n",
        "    conv6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
        "    pool3 = layers.MaxPooling2D((2, 2))(conv6)\n",
        "\n",
        "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    pool4 = layers.MaxPooling2D((2, 2))(conv7)\n",
        "\n",
        "    # Upsample\n",
        "    u3 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(pool4)\n",
        "    u3 = layers.concatenate([u3, conv7])\n",
        "    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u3)\n",
        "    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    u4 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
        "    u4 = layers.concatenate([u4, conv6])\n",
        "    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u4)\n",
        "    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VNet\n",
        "Tested, but less interesting than UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49hyPSzHUXcz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, ZeroPadding2D\n",
        "\n",
        "def conv_block(inputs, num_filters, kernel_size=(3, 3), activation='relu', padding='same'):\n",
        "    x = Conv2D(num_filters, kernel_size, padding=padding)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Conv2D(num_filters, kernel_size, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    return x\n",
        "\n",
        "def VNet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = conv_block(inputs, 16)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "    c2 = conv_block(p1, 32)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "    c3 = conv_block(p2, 64)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "    c4 = conv_block(p3, 128)\n",
        "\n",
        "    # Decoder\n",
        "    u1 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
        "    # Adjust dimensions if necessary\n",
        "    if c3.shape[1] != u1.shape[1] or c3.shape[2] != u1.shape[2]:\n",
        "        u1 = ZeroPadding2D(((0, c3.shape[1] - u1.shape[1]), (0, c3.shape[2] - u1.shape[2])))(u1)\n",
        "    u1 = layers.concatenate([u1, c3])\n",
        "    c5 = conv_block(u1, 64)\n",
        "\n",
        "    u2 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    # Adjust dimensions if necessary\n",
        "    if c2.shape[1] != u2.shape[1] or c2.shape[2] != u2.shape[2]:\n",
        "        u2 = ZeroPadding2D(((0, c2.shape[1] - u2.shape[1]), (0, c2.shape[2] - u2.shape[2])))(u2)\n",
        "    u2 = layers.concatenate([u2, c2])\n",
        "    c6 = conv_block(u2, 32)\n",
        "\n",
        "    u3 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    # Adjust dimensions if necessary\n",
        "    if c1.shape[1] != u3.shape[1] or c1.shape[2] != u3.shape[2]:\n",
        "        u3 = ZeroPadding2D(((0, c1.shape[1] - u3.shape[1]), (0, c1.shape[2] - u3.shape[2])))(u3)\n",
        "    u3 = layers.concatenate([u3, c1])\n",
        "    c7 = conv_block(u3, 16)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss function for neural networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AAIXPDAUXcz"
      },
      "outputs": [],
      "source": [
        "# Custom weighted binary cross-entropy loss\n",
        "def weighted_binary_crossentropy(y_true, y_pred):\n",
        "    # Initialization of variables\n",
        "    weight = 34                           # Value from optimal_weight (represent imbalance in the dataset)\n",
        "    epsilon = tf.keras.backend.epsilon()  # Small value to avoid numerical instability\n",
        "    \n",
        "    # Clip predicted values to avoid log(0) or log(1)\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
        "\n",
        "    # Calculate the loss for each pixel\n",
        "    loss = -(weight * y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "    \n",
        "    # Compute the mean loss over all pixels\n",
        "    return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Method used once to calculate and initialize the optimal weight of weighted_binary_crossentropy due to the imbalance of weights (lot of black pixels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the optimal weight based on the imbalance in the dataset\n",
        "def optimal_weight(boundaries):\n",
        "    white_pixel = 0\n",
        "    black_pixel = 0\n",
        "    # Iterate through each image\n",
        "    for image in boundaries:\n",
        "        # Count white and black pixels\n",
        "        for i in range(240):\n",
        "            for j in range(428):\n",
        "                if image[i][j][0] == 0:  # Assuming the image is in RGB format and black pixels have R=0\n",
        "                    black_pixel += 1\n",
        "                else:\n",
        "                    white_pixel += 1\n",
        "    # Calculate the proportion of white pixels\n",
        "    white_proportion = white_pixel / (white_pixel + black_pixel)\n",
        "    # Calculate the optimal weight based on the proportion of white pixels\n",
        "    optimal_weight = (1 - white_proportion) / white_proportion\n",
        "    print(\"Number of white pixels:\", white_pixel)\n",
        "    print(\"Number of black pixels:\", black_pixel)\n",
        "    print(\"The optimal weight is:\", optimal_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-oVb8J8UXcz"
      },
      "outputs": [],
      "source": [
        "# Plot sample\n",
        "def plot_sample(X, y, preds, ix=None):\n",
        "    if ix is None:\n",
        "        ix = np.random.randint(0, len(X))\n",
        "    has_mask = y[ix].max() > 0\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
        "    ax[0].imshow(X[ix])\n",
        "    if has_mask:\n",
        "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[0].set_title('Original Image')\n",
        "\n",
        "    ax[1].imshow(y[ix].squeeze(), cmap='gray')\n",
        "    ax[1].set_title('True Mask')\n",
        "\n",
        "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1, cmap='gray')\n",
        "    if has_mask:\n",
        "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[2].set_title('Predicted Mask')\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mainly used to apply the post-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CraxcOKBUXc0"
      },
      "outputs": [],
      "source": [
        "# Save predictions\n",
        "def save_predictions(predictions, filenames, save_dir):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    for pred, filename in zip(predictions, filenames):\n",
        "        pred_image = (pred.squeeze() * 255).astype(np.uint8)\n",
        "        save_path = os.path.join(save_dir, filename.replace('.jpg', '_pred.png'))\n",
        "        cv2.imwrite(save_path, pred_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialization of variables\n",
        "image_dir = \"./data/train/img/\"           # Inputs path directory\n",
        "boundary_dir = \"./data/train/label_img/\"  # Labels path directory\n",
        "\n",
        "# Parameters for the training time\n",
        "total_images = len(os.listdir(image_dir))  # Number of inputs/data\n",
        "batch_data = 500                           # Used to cut the training time (to avoid kernel crash : model trained for cut of 500 images)\n",
        "epochs = 15                                # Number of epochs for the training time\n",
        "batch_size = 5                             # Number of batch size for the training time\n",
        "input_shape = (240, 428, 3)                # Adjusted to 428x240 image size\n",
        "model_save = \"unet_model\"\n",
        "\n",
        "# Create and compile the model\n",
        "model = UNet(input_shape)\n",
        "model.compile(optimizer='adam', loss=weighted_binary_crossentropy, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model in batches\n",
        "for start in range(0, total_images, batch_data):\n",
        "    print(f\"Loading images {start} to {start+batch_data}\")\n",
        "\n",
        "    # Loading inputs and labels\n",
        "    images, labels, filenames = load_images(image_dir, boundary_dir, start, batch_data)\n",
        "\n",
        "    # If any data remains\n",
        "    if len(images) == 0 or len(labels) == 0:\n",
        "        continue\n",
        "\n",
        "    # Preprocessing on data\n",
        "    images, labels = preprocess_data(images, labels)\n",
        "\n",
        "    # Split data in train and validation dataset\n",
        "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
        "\n",
        "    # Save the model after each batch\n",
        "    model.save(f\"{model_save}.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction on validation dataset to test and visualize first results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UNUrVaVZNKI"
      },
      "outputs": [],
      "source": [
        "# Predict on validation set\n",
        "valid_preds = model.predict(X_val, verbose=1)\n",
        "valid_preds = (valid_preds > 0.5).astype(np.float32)\n",
        "\n",
        "# Plot some examples\n",
        "plot_sample(X_val, y_val, valid_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict the model\n",
        "The model predict 500 images by 500 images to avoid the crash of the laptop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_custom_objects().update({\"weighted_binary_crossentropy\": weighted_binary_crossentropy})\n",
        "\n",
        "# Load the model with the custom loss function\n",
        "model_path = f\"{model_save}.h5\"\n",
        "model = load_model(model_path, custom_objects={\"weighted_binary_crossentropy\": weighted_binary_crossentropy})\n",
        "\n",
        "# Initialization of variables\n",
        "image_to_predict_dir = \"./data/train/img/\"            # Images to predict path directory\n",
        "save_dir = \"predictions/first_pred\"                   # Save prediction path directory\n",
        "total_images = len(os.listdir(image_to_predict_dir))  # Number of images to predict\n",
        "start_index = 0                                       # Start index used to start to load data at this point\n",
        "num_images_to_process = total_images                  # Number of data to load (if the kernel crash)\n",
        "batch_data = 500                                      # Used to cut the training time (to avoid kernel crash : model trained for cut of 500 images)\n",
        "\n",
        "# Load and preprocess the data\n",
        "images, boundaries, filenames = load_images(image_to_predict_dir, boundary_dir, start_index, num_images_to_process)\n",
        "images, boundaries = preprocess_data(images, boundaries)\n",
        "\n",
        "for i in range(0, num_images_to_process, batch_data):\n",
        "    end_index = min(i + batch_data, num_images_to_process)\n",
        "    \n",
        "    # Select the batch of images and boundaries\n",
        "    batch_images = images[i:end_index]\n",
        "    batch_filenames = filenames[i:end_index]\n",
        "\n",
        "    # Prediction on batch of images\n",
        "    preds = model.predict(batch_images, verbose=1)\n",
        "    preds = (preds > 0.5).astype(np.float32)\n",
        "\n",
        "    # Saving predictions and displaying a message\n",
        "    save_predictions(preds, batch_filenames, save_dir)\n",
        "    print(f\"Images from {i} to {end_index} saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After predictions, we used some post-processing technics to improve results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best method : Reducing noise by morpholocigal technics and keep the largest shape detected on the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to remove noise by applying morphological opening and closing\n",
        "def remove_noise_opening_closing(image, opening_kernel_size=(5, 5), closing_kernel_size=(5, 5)):\n",
        "    # Define kernels for opening and closing operations\n",
        "    kernel_open = np.ones(opening_kernel_size, np.uint8)\n",
        "    kernel_close = np.ones(closing_kernel_size, np.uint8)\n",
        "    \n",
        "    # Apply morphological opening\n",
        "    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel_open)\n",
        "    \n",
        "    # Apply morphological closing\n",
        "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel_close)\n",
        "    \n",
        "    return closing\n",
        "\n",
        "# Function to extract largest connected component from binary image\n",
        "def largest_connected_component(image, opening_kernel_size=(5, 5)):\n",
        "    # Threshold the image to binary\n",
        "    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "    # Define kernel for opening operation\n",
        "    kernel = np.ones(opening_kernel_size, np.uint8)\n",
        "    \n",
        "    # Apply morphological opening\n",
        "    opened_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    # Find connected components\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(opened_image, connectivity=8)\n",
        "    \n",
        "    # Find index of largest component (excluding background)\n",
        "    largest_component = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
        "    \n",
        "    # Create output image with only the largest component\n",
        "    output_image = np.zeros_like(opened_image)\n",
        "    output_image[labels == largest_component] = 255\n",
        "    \n",
        "    return output_image\n",
        "\n",
        "# Function for post-processing predicted images\n",
        "def post_processing(input_dir, output_dir):\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Get list of predicted image filenames\n",
        "    predicted_images = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n",
        "\n",
        "    # Iterate over each predicted image\n",
        "    for pred_image_name in predicted_images:\n",
        "        # Load predicted image\n",
        "        pred_image_path = os.path.join(input_dir, pred_image_name)\n",
        "        pred_image = cv2.imread(pred_image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Define opening and closing kernel sizes\n",
        "        open_size=(5,5)\n",
        "        close_size=(5,5)\n",
        "\n",
        "        # Remove noise and extract largest component\n",
        "        denoised_image = remove_noise_opening_closing(pred_image, open_size, close_size)\n",
        "        largest_component_image = largest_connected_component(denoised_image, open_size)\n",
        "\n",
        "        # Save post-processed image\n",
        "        post_processed_image_path = os.path.join(output_dir, pred_image_name)\n",
        "        cv2.imwrite(post_processed_image_path, largest_component_image)\n",
        "\n",
        "# Initialization of variables\n",
        "input_dir = \"predictions/first_pred\"       # Images to post-process (in this case : predictions by UNet)\n",
        "output_dir = \"predictions/post_processed\"  # Images post-processed\n",
        "\n",
        "# Post-processing\n",
        "post_processing(input_dir, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Edge reduction \n",
        "With this method, we wanted to reduce the edge size by using a laplacian filter to remove edges from the predictions using substraction. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Edge detection by using Laplacian filter or Canny method\n",
        "def edge_detection(image, scale=0.5, method=\"laplacian\"):\n",
        "    if method == \"laplacian\":\n",
        "        laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
        "        laplacian = np.uint8(np.absolute(laplacian) * scale)\n",
        "        return laplacian\n",
        "    elif method == \"canny\":\n",
        "        # Ensure binary image using Otsu's thresholding\n",
        "        _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Apply Canny edge detection\n",
        "        edges = cv2.Canny(binary_image, 100, 200) # Adjust thresholds if needed\n",
        "\n",
        "        return edges\n",
        "\n",
        "# Function to apply 3 edge detection to reduce the edge of the prediction\n",
        "# Substract the edge of each step and return the prediction with 3 fewer edges\n",
        "def remove_3edges(prediction):\n",
        "    # Binarization\n",
        "    binary_image = (prediction > 127).astype(np.uint8) * 255\n",
        "\n",
        "    # Apply Edge detection the first time (default : Laplacian filter)\n",
        "    edges1 = edge_detection(binary_image)\n",
        "    subtracted1 = cv2.subtract(binary_image, edges1)\n",
        "\n",
        "    # Apply Edge detection the second time (default : Laplacian filter)\n",
        "    edges2 = edge_detection(subtracted1)\n",
        "    subtracted2 = cv2.subtract(subtracted1, edges2)\n",
        "\n",
        "    # Apply Edge detection the third time (default : Laplacian filter)\n",
        "    edges3 = edge_detection(subtracted2)\n",
        "    subtracted3 = cv2.subtract(subtracted2, edges3)\n",
        "\n",
        "    return subtracted3\n",
        "\n",
        "# Function to apply X edge detection to reduce the edge of the prediction\n",
        "# Substract the edge of each step and return the prediction with X fewer edges\n",
        "# While removing edge it's possible, continue to remove edge\n",
        "def remove_some_edges(prediction, threshold=1000, max_iter=5, scale=0.5):\n",
        "    # Binarization\n",
        "    binary_image = (prediction > 127).astype(np.uint8) * 255\n",
        "    \n",
        "    # Initialization of variables\n",
        "    previous_image = binary_image  # Previous image\n",
        "    i = 0                          # Loop counter        \n",
        "    \n",
        "    # While edge can be removed \n",
        "    while i < max_iter:\n",
        "        edge = edge_detection(previous_image, scale)\n",
        "        subtracted_image = cv2.subtract(previous_image, edge)\n",
        "\n",
        "        # Difference between the current and previous image\n",
        "        difference = np.sum(np.abs(subtracted_image - previous_image))\n",
        "\n",
        "        # If the difference is below the threshold, stop the loop\n",
        "        if difference < threshold:\n",
        "            break\n",
        "\n",
        "        previous_image = subtracted_image\n",
        "        i += 1\n",
        "\n",
        "    return previous_image\n",
        "\n",
        "def subtract_images(input_dir, output_dir, threshold=1000, max_iterations=5, scale=0.5):\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Process each image in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            prediction = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if prediction is not None:\n",
        "                result = remove_some_edges(prediction, threshold, max_iterations, scale)\n",
        "                # result = remove_3edges(prediction)\n",
        "                output_path = os.path.join(output_dir, filename)\n",
        "                cv2.imwrite(output_path, result)\n",
        "\n",
        "# Initialization of variables\n",
        "input_dir = \"predictions/post_processed\"      # Images post-processed\n",
        "output_dir = \"predictions/subtracted_images\"  # Substraction between post-processed and edges detection images  \n",
        "\n",
        "# Perform the image subtraction\n",
        "subtract_images(input_dir, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Line-detection\n",
        "It's very difficult to get good results: we need to adjust perfectly the HoughLinesP parameters and have straight lines to be effective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_lines(image):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    # Use Canny edge detector\n",
        "    edges = cv2.Canny(blurred, 50, 150, apertureSize=3)\n",
        "    # Apply Hough Line Transform\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=10, minLineLength=50, maxLineGap=10)\n",
        "\n",
        "    line_image = np.zeros_like(image)\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "    return line_image\n",
        "\n",
        "def line_detection(input_dir, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is not None:\n",
        "                result = detect_lines(image)\n",
        "                output_path = os.path.join(output_dir, filename)\n",
        "                cv2.imwrite(output_path, result)\n",
        "\n",
        "# Initialization of variables\n",
        "input_dir = \"predictions/post_processed\"  # Images post-processed\n",
        "output_dir = \"predictions/detect_lines\"   # Images with lines detected\n",
        "\n",
        "# Process images\n",
        "line_detection(input_dir, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Second predictions on the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To improve results, we tried to make prediction on predicted data by UNet after a post-processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load and pre-processing predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_pred(image_dir, start, limit):\n",
        "    # Initialization of variables\n",
        "    images = []    # List to store input images\n",
        "    filenames = [] # List to store file names\n",
        "\n",
        "    # List all jpg files and sort them alphabetically\n",
        "    all_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.png')])\n",
        "\n",
        "    # Slice the sorted list to get the required range\n",
        "    selected_files = all_files[start:start+limit]\n",
        "\n",
        "    for filename in selected_files:\n",
        "        # Reading images\n",
        "        image = cv2.imread(os.path.join(image_dir, filename))\n",
        "\n",
        "        if image is not None:\n",
        "            images.append(cv2.resize(image, (428, 240)))  # Resize to 428x240\n",
        "            filenames.append(filename)\n",
        "\n",
        "    return np.array(images), filenames\n",
        "\n",
        "# Preprocess predictions\n",
        "def preprocess_pred(images):\n",
        "    # Inputs normalization\n",
        "    images = images.astype('float32') / 255.0\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction with VNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Second prediction was better with VNet pre-trained model than UNet pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_custom_objects().update({\"weighted_binary_crossentropy\": weighted_binary_crossentropy})\n",
        "\n",
        "# Load the model with the custom loss function\n",
        "model_path = 'vnet_model_4320images.h5'\n",
        "model = load_model(model_path, custom_objects={\"weighted_binary_crossentropy\": weighted_binary_crossentropy})\n",
        "\n",
        "# Initialization of variables\n",
        "pred_dir = \"./predictions_unet_15epochs_5batch_4320images/first_pred\"  # Predictions to re-predict path directory\n",
        "save_dir = \"predictions/second_pred\"                                   # Save prediction path directory\n",
        "total_images = len(os.listdir(pred_dir))                               # Number of images to predict\n",
        "start_index = 0                                                        # Start index used to start to load data at this point\n",
        "num_images_to_process = total_images                                   # Number of data to load (if the kernel crash)\n",
        "batch_data = 500                                                       # Used to cut the training time (to avoid kernel crash : model trained for cut of 500 images)\n",
        "\n",
        "# Load and preprocess the data\n",
        "images, filenames = load_pred(pred_dir, start_index, num_images_to_process)\n",
        "images = preprocess_pred(images)\n",
        "\n",
        "for i in range(0, num_images_to_process, batch_size):\n",
        "    end_index = min(i + batch_size, num_images_to_process)\n",
        "    \n",
        "    # Select the batch of images and boundaries\n",
        "    batch_images = images[i:end_index]\n",
        "    batch_filenames = filenames[i:end_index]\n",
        "\n",
        "    # Prediction on batch of images\n",
        "    second_preds = model.predict(batch_images, verbose=1)\n",
        "    second_preds = (second_preds > 0.5).astype(np.float32)\n",
        "\n",
        "    # Saving predictions and displaying a message\n",
        "    save_predictions(second_preds, batch_filenames, save_dir)\n",
        "    print(f\"Images from {i} to {end_index} saved\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
